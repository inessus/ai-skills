{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 贝叶斯分类器\n",
    "贝叶斯决策论(Bayesian decision theory)是概率框架下，实施决策的基本方法。对于分类任务来说，所有相关概率都已知的理想情况下，贝叶斯决策轮考虑如何基于这些概率和误判损失来选择最优的类别标记，下面我们以多分类任务为例，来解释其基本原理。<br >\n",
    "\n",
    "假设有N中可能的类别标记，即$Y=\\{c_1,c_2,\\dots, c_N\\}$,$\\lambda_{ij}$是将一个真实标记为$c_j$的样本误分类为$c_i$所产生的损失。基于后验概率$P(c_i|\\boldsymbol{x})$可获得将样本$\\boldsymbol{x}$分类为$c_i$所产生的期望损失(expected loss)，即在损失样本$\\boldsymbol{x}$上的条件风险(conditional risk)\n",
    "$$R(c_i | \\boldsymbol{x}) = \\sum_{j=1}^{N}\\lambda_{ij}P(c_j|x) \\tag 1$$\n",
    "我们的任务是寻找一个判定标准$h:X\\rightarrow Y$ 以最小化总风险\n",
    "$$R(h) = E_x[R(h(\\boldsymbol{x})|x)] \\tag 2$$\n",
    "显然，对每个样本$\\boldsymbol{x}$，若h能最小化风险条件R(h(x)|x)，则总风险R(h)也将被最小化,这就产生了贝叶斯判定标准(Bayes decision rule)：为最小化总体风险，只需在每个样本上选择哪个能使条件风险R(c | x)最小的类别标记。即\n",
    "$$h^{*}(x)=\\mathop{argmin}_{c\\in Y}R(c | x) \\tag 3$$\n",
    "此时，$h^{*}$称为贝叶斯最优分类器(Bayes optimal classifier)，与之对应的总体风险$R(h^{*})$称为贝叶斯风险(Bayes risk)，$1-R(h^{*})$反映了分类器所能达到的最好性能，即通过机器学习所能产生的模型精度的理论上限。\n",
    "具体来说，若目标是最小化分类错误率，则误判损失$\\lambda_{ij}$可写为：\n",
    "$$\\lambda_{ij} =\\left\\{\n",
    "\\begin{aligned}\n",
    "0  &\\quad if \\quad i=j; \\\\\n",
    "1  &\\quad otherwise. \\\\\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "此时条件风险:\n",
    "$$R(c | x) = 1- P(c | x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 极大似然估计\n",
    "估计类条件概率的一种常用策略是先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。具体的，记关于类别c的类条件概率为$P(\\boldsymbol{x}|c)$，假设$P(\\boldsymbol{x}|c)$具有确定的形式并且被参数向量$\\theta_c$唯一确定。则我们的任务就是利用训练集D估计参数$\\theta_c$,为明确起见，我们将$P(\\boldsymbol{x} | c)$记为$P(\\boldsymbol{x}|\\boldsymbol{\\theta}_c)$。<br >\n",
    "事实上，概率模型的训练过程就是参数估计(parameter estimation)过程，对于参数估计，统计学界的两个学派分别提供了不同的解决方案：频率主义学派(Frequentist)认为参数虽然未知，但却是客观存在的固定值，因此，可通过优化似然函数等准则来确定参数值；贝叶斯学派(Bayesian)认为参数是为观察到的随机变量，其本身也可有分布，因此，可假定参数服从一个先验分布，然后基于观测到的数据来计算参数的后验分布。本节介绍来自频率主义学派的极大似然估计(Maximum Likelihood Estimation 简称MLE),这是根据数据采样来估计概率分布参数的经典方法。<br >\n",
    "\n",
    "令$D_c$表示训练集D中第c类样本组成的集合，假设这样本是独立同分布的，则参数$\\boldsymbol{\\theta}_c$对于数据集$D_c$的似然是：\n",
    "$$P(D_c|\\boldsymbol{\\theta}_c) = \\prod_{\\boldsymbol{x}\\in D_c}P(\\boldsymbol{x}|\\boldsymbol{\\theta}_c) \\tag 4$$\n",
    "对$\\boldsymbol{\\theta}_c$进行极大似然估计，就是去寻找能最大化似然$P(D_c|\\theta_c)$,直观上，极大似然估计是试图在$\\theta_c$所有可能的取值中，找到一个能使数据出现“可能性”最大的值。<br >\n",
    "式子4中的连乘操作易造成下溢，通常使用对数似然(log-likelihood)\n",
    "$$LL(\\boldsymbol{\\theta}_c) = log P(D_c|\\boldsymbol{\\theta}_c)$$\n",
    "$$=\\sum_{x\\in D_c}log P(\\boldsymbol{x}|\\theta_c)$$\n",
    "此时参数$\\theta_c$的极大似然估计$\\hat{\\boldsymbol{\\theta}}_c$\n",
    "$$\\hat{\\boldsymbol{\\theta}}_c = \\mathop{argmax}_{\\hat{\\boldsymbol{\\theta}}}LL(\\boldsymbol{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 朴素贝叶斯分类器\n",
    "不难发现，基于贝叶斯公式来估计后验概率P(c|x)的主要困难在于:\n",
    "类条件概率$P(x \\vert c)$是所有属性上的联合概率，难以从有限的训练样本直接估计得到。为避开这个障碍，朴素贝叶斯分类器(naive Baytes classifier)采用了“属性条件独立性假设”(attribute conditional independence assumption)对已知类别，假设所有属性相互独立，换言之，假设每个属性独立地对分类结果发生影响。<br >\n",
    "基于属性条件独立性假设，4式可以重写为:\n",
    "$$P(c\\vert x) = \\frac{P(c)P(\\boldsymbol{x} \\vert c)}{P(\\boldsymbol{x})}=\\frac{P(c)}{P(\\boldsymbol{x})}\\prod_{i=1}^{d}P(x_i|c)$$\n",
    "其中d为属性数目$x_i$为x在第i个属性上的取值.<br >\n",
    "由于对所有类别来说P(x)相同，因此基于3式的贝叶斯判定准则有\n",
    "$$h_{nb}(\\boldsymbol{x}) = \\mathop{argmax}_{c\\in y}P(c)\\prod_{i=1}^{d}P(x_i|c) \\tag 5$$\n",
    "显然，朴素贝叶斯分类器的训练过程就是基于训练集D来估计类先验概率P(c)，并为每个属性估计条件概率$P(x_i|c)$\n",
    "令$D_c$表示训练集D中第c类样本组成的集合，若有充足的独立同分布样本，则可容易地估计出类先验概率\n",
    "$$P(c)=\\frac{\\left\\vert D_c \\right\\vert}{\\left\\vert D \\right\\vert}$$\n",
    "对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第i个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i \\vert c)$可以估计为：\n",
    "$$P(x_i \\vert c) = \\frac{\\left\\vert D_{c,x_i} \\right\\vert }{\\left\\vert D_c \\right\\vert}$$\n",
    "对于联系属性可以考虑概率密度函数，假定$p(x_i \\vert c) \\sim N(\\mu_{c,i},\\sigma^2_{c,i})$，其中$\\mu_{c,i}$和$\\sigma_{c,i}^{2}$分别是第c类样本在第i个属性上取值的均值和方差，则有\n",
    "$$p(x_i \\vert c) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{c,j}}exp\\left(-\\frac{(x_i-\\mu_{c,i})^2}{2\\mu^2_{c,i}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cytoolz import *\n",
    "from itertools import product\n",
    "from operator import *\n",
    "import torch\n",
    "\n",
    "melon = pd.DataFrame({'色泽':['青绿', '乌黑', '乌黑', '青绿', '浅白','青绿', '乌黑', '乌黑', '乌黑', '青绿', '浅白', '浅白', '青绿','浅白', '乌黑', '浅白','青绿'],\n",
    " '根蒂':['蜷缩', '蜷缩', '蜷缩', '蜷缩', '蜷缩','稍蜷', '稍蜷', '稍蜷', '稍蜷', '硬挺', '硬挺', '蜷缩', '稍蜷', '稍蜷', '稍蜷','蜷缩','蜷缩'],\n",
    " '敲声':['浊响', '沉闷', '浊响', '沉闷', '浊响','浊响', '浊响', '浊响', '沉闷', '清脆', '清脆', '浊响', '浊响', '沉闷', '浊响','浊响','沉闷'],\n",
    " '纹理':['清晰', '清晰', '清晰', '清晰', '清晰','清晰', '稍糊', '清晰', '稍糊', '清晰', '模糊', '模糊', '稍糊', '稍糊', '清晰','模糊','稍糊'],\n",
    " '脐部':['凹陷', '凹陷', '凹陷', '凹陷', '凹陷','稍凹', '稍凹', '稍凹', '稍凹', '平坦', '平坦', '平坦', '凹陷', '凹陷', '稍凹','平坦','稍凹'],\n",
    " '触感':['硬滑', '硬滑', '硬滑', '硬滑', '硬滑','软粘', '软粘', '硬滑', '硬滑', '软粘', '硬滑', '软粘', '硬滑', '硬滑', '软粘','硬滑','硬滑'],\n",
    " '密度':[0.697,0.774,0.634,0.608,0.556,0.403,0.481,0.437,0.666,0.243,0.245,0.343,0.639,0.657,0.360,0.593,0.719],\n",
    "'含糖率':[0.460,0.376,0.264,0.318,0.215,0.237,0.149,0.211,0.091,0.267,0.057,0.099,0.161,0.198,0.370,0.042,0.103],                      \n",
    " '好瓜':['是', '是', '是', '是', '是','是', '是', '是', '否', '否', '否', '否', '否', '否', '否','否','否']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['敲声', '根蒂', '纹理', '脐部', '色泽', '触感']\n",
    "# 首先估计P(c) 显然有\n",
    "def Pc(df, y):\n",
    "    return list(map(lambda x: len(df[df[y]==x])/len(df), np.unique(df[y])))\n",
    "\n",
    "# 然后为每个属性估计条件概率P(xi | c)\n",
    "def PxcSub(df, y, col):\n",
    "    def g(sz, c, t):\n",
    "        try:\n",
    "            return sz[c, t]\n",
    "        except:\n",
    "            return 0\n",
    "    sz = df.groupby([col, y])[y].count()\n",
    "    l = np.array(list(map(lambda c: list(map(lambda t: g(sz,c,t),np.unique(df[y]))), np.unique(df[col]))))\n",
    "    d = list(df.groupby([y])[y].count())\n",
    "    return l/d\n",
    "\n",
    "def PxcCon(df, y, col):\n",
    "    pass\n",
    "\n",
    "def midu(df, col, colv, y, yv):\n",
    "    mean = df[df[y]==yv][col].mean()\n",
    "    std = df[df[y]==yv][col].std()\n",
    "    return pow(np.e,-(colv-mean)*(colv-mean)/(2*std*std))/(np.sqrt(2*np.pi)*std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.33333333, 0.25      ],\n",
       "        [0.44444444, 0.75      ],\n",
       "        [0.22222222, 0.        ]]), array([[0.22222222, 0.        ],\n",
       "        [0.44444444, 0.375     ],\n",
       "        [0.33333333, 0.625     ]]), array([[0.33333333, 0.        ],\n",
       "        [0.22222222, 0.875     ],\n",
       "        [0.44444444, 0.125     ]]), array([[0.22222222, 0.625     ],\n",
       "        [0.44444444, 0.        ],\n",
       "        [0.33333333, 0.375     ]]), array([[0.22222222, 0.5       ],\n",
       "        [0.44444444, 0.125     ],\n",
       "        [0.33333333, 0.375     ]]), array([[0.66666667, 0.75      ],\n",
       "        [0.33333333, 0.25      ]])]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: PxcSub(melon, '好瓜', x), cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['敲声', '根蒂', '纹理', '脐部', '色泽', '触感']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.33333333, 0.25      ],\n",
       "        [0.44444444, 0.75      ],\n",
       "        [0.22222222, 0.        ]]), array([[0.22222222, 0.        ],\n",
       "        [0.44444444, 0.375     ],\n",
       "        [0.33333333, 0.625     ]]), array([[0.33333333, 0.        ],\n",
       "        [0.22222222, 0.875     ],\n",
       "        [0.44444444, 0.125     ]]), array([[0.22222222, 0.625     ],\n",
       "        [0.44444444, 0.        ],\n",
       "        [0.33333333, 0.375     ]]), array([[0.22222222, 0.5       ],\n",
       "        [0.44444444, 0.125     ],\n",
       "        [0.33333333, 0.375     ]]), array([[0.66666667, 0.75      ],\n",
       "        [0.33333333, 0.25      ]])]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: PxcSub(melon, '好瓜', x), cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9590115494650384"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midu(melon, '密度', 0.697,'好瓜', '是')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2033038984540718"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midu(melon, '密度', 0.697,'好瓜', '否')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7880520952044112"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midu(melon, '含糖率', 0.460,'好瓜', '是')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.066221152484369"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midu(melon, '含糖率', 0.460,'好瓜', '否')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
